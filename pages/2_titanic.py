import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix

# Lecture des donn√©es
df = pd.read_csv("train.csv")

st.title("üö¢ Projet de classification binaire Titanic")

# Cr√©ation des onglets
tab1, tab2, tab3, tab4 = st.tabs(
    ["üìä Exploration", "üìà DataVizualization", "ü§ñ Mod√©lisation", "üß™ Bac √† sable"]
)

# ===== ONGLET 1: EXPLORATION =====
with tab1:
    st.header("Exploration des donn√©es")

    st.write("### Introduction")
    st.dataframe(df.head(10))

    st.write("**Dimensions du dataset:**")
    st.write(df.shape)

    st.write("### Statistiques descriptives")
    st.dataframe(df.describe())

    if st.checkbox("Afficher les valeurs manquantes"):
        st.dataframe(df.isna().sum())

# ===== ONGLET 2: DATAVIZUALIZATION =====
with tab2:
    st.header("DataVizualization")

    col1, col2 = st.columns(2)

    with col1:
        # Graphique de survie
        fig = plt.figure()
        sns.countplot(x="Survived", data=df)
        plt.title("R√©partition de la survie")
        st.pyplot(fig)

        # Graphique du genre
        fig = plt.figure()
        sns.countplot(x="Sex", data=df)
        plt.title("R√©partition du genre des passagers")
        st.pyplot(fig)

    with col2:
        # Graphique des classes
        fig = plt.figure()
        sns.countplot(x="Pclass", data=df)
        plt.title("R√©partition des classes des passagers")
        st.pyplot(fig)

        # Distribution de l'√¢ge
        fig = sns.displot(x="Age", data=df)
        plt.title("Distribution de l'√¢ge des passagers")
        st.pyplot(fig)

    st.write("### Analyses crois√©es")

    col3, col4 = st.columns(2)

    with col3:
        # Survie par genre
        fig = plt.figure()
        sns.countplot(x="Survived", hue="Sex", data=df)
        plt.title("Survie par genre")
        st.pyplot(fig)

        # Survie par classe
        fig = sns.catplot(x="Pclass", y="Survived", data=df, kind="point")
        plt.title("Taux de survie par classe")
        st.pyplot(fig)

    with col4:
        # Survie par √¢ge et classe
        fig = sns.lmplot(x="Age", y="Survived", hue="Pclass", data=df)
        plt.title("Survie en fonction de l'√¢ge et de la classe")
        st.pyplot(fig)

        # Heatmap de corr√©lation
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(
            df.select_dtypes(include=[np.number]).corr(),
            ax=ax,
            annot=True,
            fmt=".2f",
            cmap="coolwarm",
        )
        plt.title("Matrice de corr√©lation")
        st.pyplot(fig)

# ===== ONGLET 3: MOD√âLISATION =====
with tab3:
    st.header("Mod√©lisation")

    # Pr√©paration des donn√©es
    df_model = df.drop(["PassengerId", "Name", "Ticket", "Cabin"], axis=1)
    y = df_model["Survived"]
    X_cat = df_model[["Pclass", "Sex", "Embarked"]].copy()
    X_num = df_model[["Age", "Fare", "SibSp", "Parch"]].copy()

    # Imputation des valeurs manquantes
    for col in X_cat.columns:
        X_cat[col] = X_cat[col].fillna(X_cat[col].mode()[0])

    for col in X_num.columns:
        X_num[col] = X_num[col].fillna(X_num[col].median())

    # Encodage des variables cat√©gorielles
    X_cat_scaled = pd.get_dummies(X_cat, columns=X_cat.columns)
    X = pd.concat([X_cat_scaled, X_num], axis=1)

    # S√©paration train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=123
    )

    # Normalisation
    scaler = StandardScaler()
    X_train[X_num.columns] = scaler.fit_transform(X_train[X_num.columns])
    X_test[X_num.columns] = scaler.transform(X_test[X_num.columns])

    # Fonction de pr√©diction
    def prediction(classifier):
        if classifier == "Random Forest":
            clf = RandomForestClassifier()
        elif classifier == "SVC":
            clf = SVC()
        elif classifier == "Logistic Regression":
            clf = LogisticRegression()
        clf.fit(X_train, y_train)
        return clf

    # Fonction de scores
    def scores(clf, choice):
        if choice == "Accuracy":
            return clf.score(X_test, y_test)
        elif choice == "Confusion matrix":
            return confusion_matrix(y_test, clf.predict(X_test))

    # Interface utilisateur
    st.write("### Choix du mod√®le")
    choix = ["Random Forest", "SVC", "Logistic Regression"]
    option = st.selectbox("Choix du mod√®le", choix)
    st.write("Le mod√®le choisi est :", option)

    # Entra√Ænement du mod√®le
    clf = prediction(option)

    # Affichage des r√©sultats
    st.write("### R√©sultats")
    display = st.radio("Que souhaitez-vous montrer ?", ("Accuracy", "Confusion matrix"))

    if display == "Accuracy":
        accuracy = scores(clf, display)
        st.metric("Accuracy", f"{accuracy:.4f}")
    elif display == "Confusion matrix":
        st.write("**Matrice de confusion:**")
        cm = scores(clf, display)
        st.dataframe(
            pd.DataFrame(
                cm,
                columns=["Pr√©dit Non-Survivant", "Pr√©dit Survivant"],
                index=["R√©el Non-Survivant", "R√©el Survivant"],
            )
        )

# ===== ONGLET 4: BAC √Ä SABLE =====
with tab4:
    st.header("Bac √† sable")

    st.write("### G√©n√©ration de valeurs al√©atoires")

    import random

    @st.cache_data
    def generate_random_value(x):
        return random.uniform(0, x)

    a = generate_random_value(10)
    b = generate_random_value(20)

    col1, col2 = st.columns(2)

    with col1:
        st.metric("Valeur al√©atoire a (0-10)", f"{a:.2f}")

    with col2:
        st.metric("Valeur al√©atoire b (0-20)", f"{b:.2f}")

    st.info(
        "üí° Ces valeurs sont mises en cache et ne changeront pas tant que vous ne relancez pas l'application."
    )
